{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Algorithmic Collusion\n",
    "\n",
    "## Background\n",
    "The Netherlands Authority for Consumers and Markets (ACM) is an antitrust authority. Its primary goal is to ensure fair competition and protect consumers from anticompetitive practices. With the rise of artificial intelligence (AI) and machine learning, a new challenge has emerged: algorithmic collusion. This phenomenon occurs when algorithms, designed to optimize pricing strategies, inadvertently or deliberately engage in collusive behaviour, leading to supra-competitive prices. \n",
    "\n",
    "## Understanding Algorithmic Collusion\n",
    "Algorithmic collusion refers to the situation where pricing algorithms, often used by companies to set prices dynamically, result in higher prices than in traditional competition. Unlike human collusion, where firms explicitly agree to fix prices, algorithmic collusion can occur without any direct communication between firms. Instead, it arises from the algorithms' learning processes and their responses to market conditions. \n",
    "The outcomes of theoretical simulations of early studies reported in e.g. Calvano et al. (2020) and Klein (2021) have generated algorithmic collusion. Recently, Xavier Lambin  and co-authors have challenged these results and attributed algorithmic collusion to the simultaneous setup of the simulations, see e.g. Abada and Lambin (2023) and Lambin (2024). \n",
    "\n",
    "\n",
    "# Key Concerns\n",
    "1.\tSimultaneous Experimentation: Algorithms often experiment with different pricing strategies simultaneously. This can lead to high prices as they learn from each other's actions.\n",
    "2.\tLearning Inertia: Reinforcement learning algorithms may exhibit inertia, where initial high prices persist over time due to the learning process.\n",
    "3.\tMemoryless Environments: Even in environments where algorithms do not consider past actions, high prices can still emerge.\n",
    "Policy Implications\n",
    "Traditional antitrust measures may not be sufficient to address algorithmic collusion. Reducing market transparency, for example, may not effectively lower prices. Instead, the ACM needs to consider new approaches, such as enforcing sequential learning, where algorithms take turns exploring pricing strategies.\n",
    "\n",
    "ME case: Running Simulations\n",
    "To better understand algorithmic collusion, the ACM has hired you as a consultant to run simulations. Here’s a step-by-step guide:\n",
    "1.\tSet Up the Environment: Use a programming language like R or Python (and libraries such as NumPy and Matplotlib).\n",
    "2.\tDefine the Market: Set up a market with two firms, each using a Q-learning algorithm. You may consider either homogeneous or differentiated products, competition in either prices (Bertrand) or quantities (Cournot) and whether prices are set either simultaneously (Lambin, 2024) or sequentially (Klein, 2021). One combination suffices.\n",
    "3.\tImplement Q-Learning: Create a Q-learning algorithm that simulates decisions in your duopoly market.\n",
    "4.\tRun Simulations: Allow the algorithms to explore and exploit strategies over multiple iterations similar as in the literature.\n",
    "5.\tAnalyse Results: Observe whether the algorithms converge to high prices and compare the results to the findings in the literature.\n",
    "6.\tPolicy Recommendations: Use your simulations to report to the ACM whether algorithmic collusion is a threat (or not). It would be nice to calculate welfare effects, such as the gain in producer surplus, the loss of consumer surplus and the deadweight loss.   \n",
    "By running these simulations, you gain hands-on experience with the dynamics of algorithmic collusion and explore potential policy interventions to mitigate its effects.\n",
    "Summary\n",
    "Algorithmic collusion presents a significant challenge for antitrust authorities. By understanding the mechanisms behind it and exploring innovative solutions, we can better protect consumers and ensure fair competition in the digital age.\n",
    "Resources\n",
    "The source code of Calvano et al. (2020) is available at the website of the American Economic Review. Unfortunately, their source code is in R instead of Python. Also, Abada and Lambin (2023) provide their source code in R for a duopoly with inventories (not asked). \n",
    "For the use of ChatGPT or similar AI the plagiarism rules of this course apply. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we follow the work of Calvano et al (2020) in order to create a simulation of the algorithmic collusion case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider two firms (1 and 2) that produce differentiated products. Demand for wach product is defined by the following function: \n",
    "\n",
    "\n",
    "\n",
    "$$ q_{1, t} = \\frac{e^\\frac{2 - p_{1, t}}{1/4}}{e^{\\frac{2 - p_{1, t}}{1/4}} +  e^{\\frac{2 - p_{2, t}}{1/4}} + 1}$$\n",
    "\n",
    "$$ q_{2, t} = \\frac{e^\\frac{2 - p_{1, t}}{1/4}}{e^{\\frac{2 - p_{1, t}}{1/4}} +  e^{\\frac{2 - p_{2, t}}{1/4}} + 1}$$\n",
    "\n",
    "\n",
    "Firms are interested in profit maximization. They will choose prices such that they maximize their profits. In these equations we have: \n",
    "\n",
    "\n",
    "The profit each firm earns is given by: \n",
    "\n",
    "$$ \\pi_{1, t} = (p_{1, t} - 1) q_{1, t}$$\n",
    "\n",
    "$$ \\pi_{2, t} = (p_{2, t} - 1) q_{2, t}$$\n",
    "\n",
    "Where we recognize that 1 represent the marginal cost of the firm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our simulation we will use object-oriented programming. Please before continuing with the assignment, if this concept is new for you, watch the following Youtube video. We parametrize our simulation using the values from baseline parametrization and initalization from Calvano et al. (2020). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the following required modules. \n",
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Market():\n",
    "\n",
    "    '''\n",
    "    Define the firm class considering all the important characteristics a firm \n",
    "    will have\n",
    "    '''\n",
    "    def __init__(self, \n",
    "        number_of_firms = 2, \n",
    "        number_of_periods = 0 ):\n",
    "\n",
    "        self.number_of_firms = number_of_firms\n",
    "        self.numer_of_periods = number_of_periods\n",
    "\n",
    "        self.a  = 2\n",
    "        self.c = 1\n",
    "        self.mu = 1/4\n",
    "\n",
    "        # Initialize each period price as a vector of zeros\n",
    "        self.price = np.zeros((self.number_of_firms, self.numer_of_periods))\n",
    "\n",
    "        # Initialize each periof quantitity as a vector of zeros\n",
    "        self.quantity = np.zeros((self.number_of_firms, self.numer_of_periods))\n",
    "\n",
    "        self.profits = np.zeros((self.number_of_firms, self.numer_of_periods))\n",
    "\n",
    "\n",
    "    def firm_demand(self):\n",
    "\n",
    "        ul  = np.exp((self.a - self.price)/(self.mu))\n",
    "        sum_ul = np.sum(ul, axis = 0)\n",
    "        q = ul/(sum_ul+1)\n",
    "\n",
    "        return q\n",
    "    \n",
    "    def construct_Jacobian(self): \n",
    "        \"\"\" Formulas for the matrix of first order conditions of market\n",
    "        shares with respect to prices \n",
    "\n",
    "        Args:\n",
    "            v_p (float): random consumer demand shocks\n",
    "            all_probs (float): the probability a consumer i buy a product j \n",
    "\n",
    "        Returns:\n",
    "            float matrix : the Jacobian matrix of shares with respect to prices \n",
    "\n",
    "        updated version that should be giving the corrent result in the end \n",
    "        This needs to be further debugged because i think it doesn't some\n",
    "        across correctly \n",
    "        \"\"\"\n",
    "        J = np.zeros((self.number_of_firms, self.number_of_firms))\n",
    "        for i in range(J.shape[0]):\n",
    "            p1 = all_probs[i, :]\n",
    "            for j in range(J.shape[1]):\n",
    "                if i == j:\n",
    "                    J[i, j] = np.sum(alphas * p1 - alphas * (p1 ** 2))/self.n_consumers\n",
    "                else: \n",
    "                    p2 = all_probs[j, :]\n",
    "                    J[i, j] = np.sum(-alphas * p1 * p2)/self.n_consumers\n",
    "        return J\n",
    "\n",
    "    \n",
    "    def firm_profit(self, prices):\n",
    "\n",
    "        self.price = prices\n",
    "        self.quantity = self.firm_demand()\n",
    "\n",
    "        pi = (self.price - self.c)*self.quantity\n",
    "\n",
    "        return - pi\n",
    "\n",
    "\n",
    "    def compute_NB_equilibrium(self): \n",
    "\n",
    "        price_initial = np.ones(self.number_of_firms)\n",
    "\n",
    "        res = minimize(self.firm_profit, price_initial)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "\n",
    "    def compute_monopoly_equilibiurm(self): \n",
    "\n",
    "        return \n",
    "\n",
    "    def compute_Q_learning_equilibirum(self):\n",
    "\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: \n",
    "\n",
    "Compute the Bertrand-Nash equilibiurm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The user-provided objective function must return a scalar value.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:141\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     fx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your code here for computing Nash Bertrand Equilibiurm \u001b[39;00m\n\u001b[1;32m      3\u001b[0m market \u001b[38;5;241m=\u001b[39m Market()\n\u001b[0;32m----> 5\u001b[0m vb \u001b[38;5;241m=\u001b[39m \u001b[43mmarket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_NB_equilibrium\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(vb)\n",
      "Cell \u001b[0;32mIn[38], line 49\u001b[0m, in \u001b[0;36mMarket.compute_NB_equilibrium\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_NB_equilibrium\u001b[39m(\u001b[38;5;28mself\u001b[39m): \n\u001b[1;32m     47\u001b[0m     price_initial \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_firms)\n\u001b[0;32m---> 49\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirm_profit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice_initial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_minimize.py:705\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    703\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 705\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_bfgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_optimize.py:1419\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, xrtol, **unknown_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxiter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1417\u001b[0m     maxiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x0) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m-> 1419\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m f \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m   1423\u001b[0m myfprime \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_optimize.py:383\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    379\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_differentiable_functions.py:143\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m         fx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(fx)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe user-provided objective function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust return a scalar value.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m x\n",
      "\u001b[0;31mValueError\u001b[0m: The user-provided objective function must return a scalar value."
     ]
    }
   ],
   "source": [
    "# Your code here for computing Nash Bertrand Equilibiurm \n",
    "\n",
    "market = Market()\n",
    "\n",
    "vb = market.compute_NB_equilibrium()\n",
    "\n",
    "print(vb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: \n",
    "\n",
    "Compute the Monopoly (perfect collusion equilibiurm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for computing Nash Bertrand Equilibiurm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: \n",
    "\n",
    "Compute the Q-learning algorith: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "Abada, Ibrahim and Xavier Lambin. 2023. Artificial Intelligence: Can Seemingly Collusive Outcomes Be Avoided? Management Science 69 (9): 5042-5065. DOI: 10.1287/mnsc.2022.4623\n",
    "\n",
    "Calvano, Emilio, Giacomo Calzolari, Vincenzo Denicolò, and Sergio Pastorello. 2020. \"Artificial Intelligence, Algorithmic Pricing, and Collusion.\" American Economic Review 110 (10): 3267–97. DOI: 10.1257/aer.20190623\n",
    "\n",
    "Klein, Timo. 2021. “Autonomous algorithmic collusion: Q-learning under sequential pricing.” RAND Journal of Economics 52 (3): 538-558. DOI: 10.1111/1756-2171.12383\n",
    "\n",
    "Lambin, Xavier. 2024. Less than meets the eye: simultaneous experiments as a source of algorithmic seeming collusion. Available at SSRN: https://ssrn.com/abstract=4498926 or http://dx.doi.org/10.2139/ssrn.4498926\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment developed by Harold Houba and Ana Popovici"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
